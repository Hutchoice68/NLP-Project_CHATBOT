# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô: pip install pythainlp

import os
import pickle
import requests
import numpy as np
from linebot.v3.messaging import TextMessage
from datetime import datetime
from dotenv import load_dotenv

# ‚ú® ‡πÉ‡∏ä‡πâ PyThaiNLP ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏ó‡∏µ‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥
try:
    from pythainlp.tokenize import word_tokenize
    USE_PYTHAINLP = True
    print("‚úÖ PyThaiNLP loaded successfully")
except ImportError:
    USE_PYTHAINLP = False
    print("‚ö†Ô∏è PyThaiNLP not found - using simple tokenizer")
    import re

# ‡πÇ‡∏´‡∏•‡∏î .env
load_dotenv(override=True)

MODEL_PATH = os.getenv('MODEL_PATH', 'thai_intent_model.pkl')

# ===== MOCK DATABASE =====
MOCK_PRODUCTS = [
    {
        "product_id": 1,
        "product_name": "‡πÄ‡∏™‡∏∑‡πâ‡∏≠‡∏¢‡∏∑‡∏î‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß",
        "description": "‡πÄ‡∏™‡∏∑‡πâ‡∏≠‡∏¢‡∏∑‡∏î‡∏Ñ‡∏≠‡∏Å‡∏•‡∏°‡∏ú‡πâ‡∏≤‡∏Ñ‡∏≠‡∏ï‡∏ï‡∏≠‡∏ô 100% ‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß ‡πÉ‡∏™‡πà‡∏™‡∏ö‡∏≤‡∏¢",
        "price": 299,
        "stock": 50,
        "keywords": ["‡πÄ‡∏™‡∏∑‡πâ‡∏≠", "‡πÄ‡∏™‡∏∑‡πâ‡∏≠‡∏¢‡∏∑‡∏î", "‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß", "‡∏ú‡πâ‡∏≤", "‡∏Ñ‡∏≠‡∏ï‡∏ï‡∏≠‡∏ô"],
    },
    {
        "product_id": 2,
        "product_name": "‡∏Å‡∏≤‡∏á‡πÄ‡∏Å‡∏á‡∏¢‡∏µ‡∏ô‡∏™‡πå",
        "description": "‡∏Å‡∏≤‡∏á‡πÄ‡∏Å‡∏á‡∏¢‡∏µ‡∏ô‡∏™‡πå‡∏Ç‡∏≤‡∏¢‡∏≤‡∏ß ‡∏ó‡∏£‡∏á‡∏™‡∏•‡∏¥‡∏° ‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏Ç‡πâ‡∏°",
        "price": 890,
        "stock": 30,
        "keywords": ["‡∏Å‡∏≤‡∏á‡πÄ‡∏Å‡∏á", "‡∏¢‡∏µ‡∏ô‡∏™‡πå", "‡∏Ç‡∏≤‡∏¢‡∏≤‡∏ß", "‡∏™‡∏•‡∏¥‡∏°", "‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô"],
    },
    {
        "product_id": 3,
        "product_name": "‡∏£‡∏≠‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏ú‡πâ‡∏≤‡πÉ‡∏ö",
        "description": "‡∏£‡∏≠‡∏á‡πÄ‡∏ó‡πâ‡∏≤‡∏ú‡πâ‡∏≤‡πÉ‡∏ö‡∏™‡∏µ‡∏î‡∏≥ ‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡πÄ‡∏ö‡∏≤ ‡πÉ‡∏™‡πà‡∏™‡∏ö‡∏≤‡∏¢",
        "price": 1290,
        "stock": 20,
        "keywords": ["‡∏£‡∏≠‡∏á‡πÄ‡∏ó‡πâ‡∏≤", "‡∏ú‡πâ‡∏≤‡πÉ‡∏ö", "‡∏™‡∏µ‡∏î‡∏≥", "‡πÄ‡∏ö‡∏≤"],
    },
    {
        "product_id": 4,
        "product_name": "‡∏Å‡∏£‡∏∞‡πÄ‡∏õ‡πã‡∏≤‡∏™‡∏∞‡∏û‡∏≤‡∏¢‡∏Ç‡πâ‡∏≤‡∏á",
        "description": "‡∏Å‡∏£‡∏∞‡πÄ‡∏õ‡πã‡∏≤‡∏ú‡πâ‡∏≤‡πÅ‡∏Ñ‡∏ô‡∏ß‡∏≤‡∏™ ‡∏Ç‡∏ô‡∏≤‡∏î‡∏Å‡∏•‡∏≤‡∏á ‡∏™‡∏∞‡∏û‡∏≤‡∏¢‡∏Ç‡πâ‡∏≤‡∏á‡∏™‡∏ö‡∏≤‡∏¢",
        "price": 450,
        "stock": 15,
        "keywords": ["‡∏Å‡∏£‡∏∞‡πÄ‡∏õ‡πã‡∏≤", "‡∏™‡∏∞‡∏û‡∏≤‡∏¢", "‡πÅ‡∏Ñ‡∏ô‡∏ß‡∏≤‡∏™"],
    },
    {
        "product_id": 5,
        "product_name": "‡∏´‡∏°‡∏ß‡∏Å‡πÅ‡∏Å‡πä‡∏õ",
        "description": "‡∏´‡∏°‡∏ß‡∏Å‡πÅ‡∏Å‡πä‡∏õ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏î‡πâ ‡∏ú‡πâ‡∏≤‡∏Ñ‡∏≠‡∏ï‡∏ï‡∏≠‡∏ô",
        "price": 250,
        "stock": 40,
        "keywords": ["‡∏´‡∏°‡∏ß‡∏Å", "‡πÅ‡∏Å‡πä‡∏õ", "‡∏Ñ‡∏≠‡∏ï‡∏ï‡∏≠‡∏ô"],
    }
]

MOCK_ORDERS = {
    "U1234567890": [
        {
            "order_id": "ORD001",
            "product_name": "‡πÄ‡∏™‡∏∑‡πâ‡∏≠‡∏¢‡∏∑‡∏î‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß",
            "status": "‡∏à‡∏±‡∏î‡∏™‡πà‡∏á‡πÅ‡∏•‡πâ‡∏ß",
            "created_at": "2025-10-15 10:30:00",
        }
    ],
    "default": [
        {
            "order_id": "ORD999",
            "product_name": "‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á",
            "status": "‡∏£‡∏≠‡∏ä‡∏≥‡∏£‡∏∞‡πÄ‡∏á‡∏¥‡∏ô",
            "created_at": "2025-10-17 09:00:00",
        }
    ]
}

# ===== LOAD MODEL =====
intent_model = None
model_components = None

try:
    with open(MODEL_PATH, 'rb') as f:
        loaded_data = pickle.load(f)
    
    if isinstance(loaded_data, dict):
        model_components = loaded_data
        intent_model = 'hybrid'
        print(f"‚úÖ Loaded hybrid model from: {MODEL_PATH}")
    else:
        intent_model = loaded_data
        print(f"‚úÖ Loaded intent model from: {MODEL_PATH}")
except:
    print(f"‚ö†Ô∏è Model not found - using rule-based")


# ==========================
# Thai Text Processing
# ==========================
def thai_tokenize(text):
    """‚ú® ‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏≥‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ - ‡πÉ‡∏ä‡πâ PyThaiNLP ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ, ‡πÑ‡∏°‡πà‡πÄ‡∏ä‡πà‡∏ô‡∏ô‡∏±‡πâ‡∏ô‡πÉ‡∏ä‡πâ fallback"""
    if USE_PYTHAINLP:
        tokens = word_tokenize(text, engine='newmm', keep_whitespace=False)
        tokens = [t for t in tokens if len(t.strip()) >= 2 and not t.isspace()]
        return tokens
    else:
        THAI_DICT = [
            '‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£', '‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î', '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•', '‡∏Å‡∏≤‡∏á‡πÄ‡∏Å‡∏á', '‡πÄ‡∏™‡∏∑‡πâ‡∏≠', '‡∏£‡∏≠‡∏á‡πÄ‡∏ó‡πâ‡∏≤',
            '‡∏Å‡∏£‡∏∞‡πÄ‡∏õ‡πã‡∏≤', '‡∏´‡∏°‡∏ß‡∏Å', '‡∏£‡∏≤‡∏Ñ‡∏≤', '‡∏™‡∏ï‡πá‡∏≠‡∏Å', '‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠', '‡∏Ñ‡∏∑‡∏ô‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤',
            '‡∏¢‡∏µ‡∏ô‡∏™‡πå', '‡∏ú‡πâ‡∏≤‡πÉ‡∏ö', '‡∏™‡∏µ‡∏Ç‡∏≤‡∏ß', '‡∏™‡∏µ‡∏î‡∏≥', '‡∏Ñ‡∏≠‡∏ï‡∏ï‡∏≠‡∏ô', '‡∏Ç‡∏≠', '‡∏î‡∏π', '‡∏°‡∏µ'
        ]
        THAI_DICT.sort(key=len, reverse=True)
        
        text = re.sub(r'[^\u0E00-\u0E7Fa-zA-Z0-9\s]', '', text.lower())
        found = []
        i = 0
        while i < len(text):
            matched = False
            for word in THAI_DICT:
                if text[i:i+len(word)] == word:
                    found.append(word)
                    i += len(word)
                    matched = True
                    break
            if not matched:
                i += 1
        return list(set(found))


# ==========================
# Database Functions
# ==========================
def get_product_info(product_name=None, limit=5):
    """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤"""
    print(f"üîç get_product_info: '{product_name}'")
    
    if product_name:
        search_terms = thai_tokenize(product_name)
        print(f"   Tokens: {search_terms}")
        
        if not search_terms:
            search_terms = [product_name.lower()]
        
        results = []
        for p in MOCK_PRODUCTS:
            searchable = (
                f"{p['product_name']} {p['description']} "
                f"{' '.join(p.get('keywords', []))}"
            ).lower()
            
            match_count = sum(1 for t in search_terms if t in searchable)
            if match_count > 0:
                results.append((p, match_count))
                print(f"   ‚úÖ {p['product_name']} (score: {match_count})")
        
        results.sort(key=lambda x: x[1], reverse=True)
        return [p[0] for p in results[:limit]]
    
    return MOCK_PRODUCTS[:limit]


def get_order_info(user_id=None, order_id=None):
    """‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠"""
    if order_id:
        for orders in MOCK_ORDERS.values():
            for o in orders:
                if o['order_id'] == order_id:
                    return [o]
        return []
    elif user_id:
        return MOCK_ORDERS.get(user_id, MOCK_ORDERS.get("default", []))[:5]
    return []


# ==========================
# LLM (Ollama Local)
# ==========================
def call_ollama_llm(prompt, context=""):
    """‡πÄ‡∏£‡∏µ‡∏¢‡∏Å LLM ‡∏à‡∏≤‡∏Å Ollama ‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á"""
    try:
        print(f"üîÑ Calling Ollama...")

        # üîß ‡∏ï‡∏±‡πâ‡∏á‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏°‡∏µ ‡πÄ‡∏ä‡πà‡∏ô "llama3.2" ‡∏´‡∏£‡∏∑‡∏≠ "qwen2.5"
        model_name = "llama3.2"

        system_prompt = f"‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏£‡πâ‡∏≤‡∏ô‡∏Ñ‡πâ‡∏≤ ‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡∏™‡∏±‡πâ‡∏ô‡πÜ 2-3 ‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ\n\n‡∏ö‡∏£‡∏¥‡∏ö‡∏ó:\n{context}\n\n‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ: {prompt}"

        payload = {
            "model": model_name,
            "prompt": system_prompt,
            "stream": False
        }

        response = requests.post(
            "http://localhost:11434/api/generate",
            json=payload,
            timeout=30
        )

        if response.status_code == 200:
            data = response.json()
            answer = data.get("response", "").strip()
            print(f"   ‚úÖ Ollama Response OK")
            return answer
        else:
            print(f"   ‚ùå Ollama Error {response.status_code}: {response.text}")
            return None

    except Exception as e:
        print(f"‚ùå Ollama Error: {e}")
        return None


# ==========================
# Intent Prediction
# ==========================
def predict_intent(text):
    """‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢ Intent"""
    global intent_model, model_components
    
    if intent_model == 'hybrid' and model_components:
        try:
            semantic_model = model_components['semantic']
            tfidf_vectorizer = model_components['tfidf']
            clf = model_components['clf']
            
            semantic_features = semantic_model.encode([text])
            tfidf_features = tfidf_vectorizer.transform([text]).toarray()
            
            scaler_sem = model_components.get('scaler_sem')
            scaler_tfidf = model_components.get('scaler_tfidf')
            
            if scaler_sem:
                semantic_features = scaler_sem.transform(semantic_features)
            if scaler_tfidf:
                tfidf_features = scaler_tfidf.transform(tfidf_features)
            
            alpha = model_components.get('alpha', 0.5)
            beta = model_components.get('beta', 0.5)
            
            combined = np.hstack([alpha * semantic_features, beta * tfidf_features])
            intent = clf.predict(combined)[0]
            print(f"üéØ Intent: {intent}")
            return intent
        except Exception as e:
            print(f"‚ö†Ô∏è Model error: {e}")
    
    # Rule-based fallback
    text_lower = text.lower()
    if any(w in text_lower for w in ['‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ', 'hello', 'hi']):
        return "greeting"
    elif any(w in text_lower for w in ['‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì', 'thank']):
        return "thank_you"
    elif any(w in text_lower for w in ['‡∏™‡∏±‡πà‡∏á', '‡∏ã‡∏∑‡πâ‡∏≠', 'order']):
        return "order_product"
    elif any(w in text_lower for w in ['‡∏Ñ‡∏∑‡∏ô', 'refund', '‡πÄ‡∏Ñ‡∏•‡∏°']):
        return "refund_request"
    elif any(w in text_lower for w in ['‡∏ä‡πà‡∏ß‡∏¢', 'help', '‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°']):
        return "help_request"
    elif any(w in text_lower for w in ['‡∏£‡∏≤‡∏Ñ‡∏≤', '‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤', '‡πÄ‡∏™‡∏∑‡πâ‡∏≠', '‡∏Å‡∏≤‡∏á‡πÄ‡∏Å‡∏á', '‡∏£‡∏≠‡∏á‡πÄ‡∏ó‡πâ‡∏≤']):
        return "ask_info"
    elif any(w in text_lower for w in ['‡∏£‡∏µ‡∏ß‡∏¥‡∏ß', 'feedback']):
        return "feedback"
    else:
        return "unknown"


# ==========================
# Intent Response
# ==========================
def handle_intent_response(intent, user_message, user_id):
    """‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°"""
    if intent == "greeting":
        return "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö! ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏∞ üòä"
    elif intent == "thank_you":
        return "‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö! ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÑ‡∏´‡∏°‡∏Ñ‡∏∞ üôè"
    elif intent == "ask_info":
        products = get_product_info(user_message, limit=3)
        if products:
            context = "\n".join([
                f"- {p['product_name']}: {p['price']} ‡∏ö‡∏≤‡∏ó, {p['description']}, ‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠ {p['stock']} ‡∏ä‡∏¥‡πâ‡∏ô"
                for p in products
            ])
            llm_response = call_ollama_llm(user_message, f"‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤:\n{context}")
            if llm_response:
                return llm_response
            product_list = "\n".join([
                f"‚Ä¢ {p['product_name']}\n  üí∞ {p['price']} ‡∏ö‡∏≤‡∏ó\n  üì¶ ‡∏Ñ‡∏á‡πÄ‡∏´‡∏•‡∏∑‡∏≠ {p['stock']} ‡∏ä‡∏¥‡πâ‡∏ô"
                for p in products
            ])
            return f"‚ú® ‡∏û‡∏ö‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏™‡∏ô‡πÉ‡∏à:\n\n{product_list}\n\n‡∏™‡∏ô‡πÉ‡∏à‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠‡πÑ‡∏´‡∏°‡∏Ñ‡∏∞?"
        else:
            return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ üòÖ\n\n‡∏•‡∏≠‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤: ‡πÄ‡∏™‡∏∑‡πâ‡∏≠, ‡∏Å‡∏≤‡∏á‡πÄ‡∏Å‡∏á, ‡∏£‡∏≠‡∏á‡πÄ‡∏ó‡πâ‡∏≤, ‡∏Å‡∏£‡∏∞‡πÄ‡∏õ‡πã‡∏≤, ‡∏´‡∏°‡∏ß‡∏Å"
    elif intent == "order_product":
        orders = get_order_info(user_id=user_id)
        if orders:
            order_list = "\n".join([f"‚Ä¢ {o['order_id']}: {o['status']}" for o in orders[:2]])
            return f"‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì:\n{order_list}"
        return "‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÑ‡∏´‡∏°‡∏Ñ‡∏∞? ‡∏ö‡∏≠‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡πà‡∏∞"
    elif intent == "refund_request":
        return "‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏Ñ‡∏∑‡∏ô‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤‡πÑ‡∏î‡πâ‡∏†‡∏≤‡∏¢‡πÉ‡∏ô 7 ‡∏ß‡∏±‡∏ô ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÅ‡∏à‡πâ‡∏á‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠‡∏Ñ‡πà‡∏∞ üì¶"
    elif intent == "help_request":
        return "‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏Ñ‡∏£‡∏±‡∏ö! ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á:\n‚Ä¢ ‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤\n‚Ä¢ ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏ã‡∏∑‡πâ‡∏≠\n‚Ä¢ ‡∏Å‡∏≤‡∏£‡∏Ñ‡∏∑‡∏ô‡∏™‡∏¥‡∏ô‡∏Ñ‡πâ‡∏≤"
    elif intent == "feedback":
        return "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Feedback ‡∏Ñ‡∏£‡∏±‡∏ö! ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏ô‡∏≥‡πÑ‡∏õ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡∏Ñ‡πà‡∏∞ üí™"
    else:
        return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö ‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡∏•‡∏≠‡∏á‡∏ñ‡∏≤‡∏°‡πÉ‡∏´‡∏°‡πà‡πÑ‡∏î‡πâ‡πÑ‡∏´‡∏°‡∏Ñ‡∏∞? ü§î"


# ==========================
# Main Response
# ==========================
def reponse_message(event):
    """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏´‡∏•‡∏±‡∏Å"""
    user_message = event.message.text.strip()
    user_id = getattr(event.source, 'user_id', 'default')
    
    print(f"\n{'='*50}")
    print(f"üì® Message: {user_message}")
    print(f"üë§ User: {user_id}")
    
    intent = predict_intent(user_message)
    response = handle_intent_response(intent, user_message, user_id)
    
    print(f"üí¨ Response: {response}")
    print(f"{'='*50}\n")
    
    return TextMessage(text=response)
